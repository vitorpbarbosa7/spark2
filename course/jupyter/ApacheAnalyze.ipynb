{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ace5dd3-9ea9-4b23-859e-bdbd7f9b8605",
   "metadata": {},
   "source": [
    "# Sample Apache Spark Notebook\n",
    "\n",
    "Here's an example of cleaning and analyzing an Apache access log, but this time within an interactive Notebook environment!\n",
    "\n",
    "While prototyping data engineering solutions, notebook environments are popular.\n",
    "\n",
    "If you installed the pyspark package or are working within an already-established environment for Spark, things will probably \"just work.\" But if not, using the findspark package will tie the notebook to your existing Spark installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910ebf75-0a78-4b7f-9abc-d8fdd0093093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e663604-b27d-4b02-bade-5e11f46a0a4a",
   "metadata": {},
   "source": [
    "One nice thing about notebooks is that you can leave little comments and explanations like this, in markdown format.\n",
    "\n",
    "We'll start by importing the stuff we need, and creating a SparkSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944a1921-c630-4280-90b0-5d662480bd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/11 08:06:07 WARN Utils: Your hostname, bitedFruit.local, resolves to a loopback address: 127.0.0.1; using 192.168.15.3 instead (on interface en0)\n",
      "25/11/11 08:06:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/11 08:06:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract, col, count, desc\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"ApacheLogAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bfe8e-97cc-4520-b2ed-8066bfeab7e4",
   "metadata": {},
   "source": [
    "Next we'll load up our sample access log, and load in the raw text into a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34f70e75-94d2-4fc4-9362-dc5d9cd6135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log file path (Update this path to your log file location)\n",
    "log_file = \"./access_log.txt\"\n",
    "\n",
    "# Read log file as text\n",
    "logs_df = spark.read.text(log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2fefad-fb71-49eb-8eda-a2482d7579b3",
   "metadata": {},
   "source": [
    "We'll now parse the log into the fields we are interested in. Note, we know there is some bad data in here where the status code is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ece337f-2f61-49b1-8b72-56cdec462fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression pattern to extract fields\n",
    "log_pattern = r'(\\S+) - - \\[(.*?)\\] \"(.*?)\" (\\S{3}) (\\d+) \"(.*?)\"'\n",
    "\n",
    "# Extract fields using regex\n",
    "parsed_logs_df = logs_df.select(\n",
    "    regexp_extract('value', log_pattern, 1).alias(\"ip_address\"),\n",
    "    regexp_extract('value', log_pattern, 2).alias(\"timestamp\"),\n",
    "    regexp_extract('value', log_pattern, 3).alias(\"request\"),\n",
    "    regexp_extract('value', log_pattern, 4).alias(\"status\"),\n",
    "    regexp_extract('value', log_pattern, 5).cast(\"integer\").alias(\"bytes\"),\n",
    "    regexp_extract('value', log_pattern, 6).alias(\"user_agent\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c6194c-6691-41c4-987b-19ec9d2c792f",
   "metadata": {},
   "source": [
    "We'll use a filter to just remove those bogus rows with no status, and cast the remaining status codes to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99c34fb-fc1b-47e1-8ef9-d699f2664ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with empty status fields\n",
    "cleaned_df = parsed_logs_df.filter(col(\"status\").isNotNull() & (col(\"status\") != \"\"))\n",
    "cleaned_df = cleaned_df.withColumn(\"status\", col(\"status\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b06dcd-a1d8-4af9-800f-672cd50c41f3",
   "metadata": {},
   "source": [
    "A nice thing about notebooks is you can break up your processing into these separate blocks, and inspect the output just for whatever it is you're doing. Then you can go back and iterate on that piece of code as needed, rather than re-running everything.\n",
    "\n",
    "Let's further process our data to split out the method and endpoint from the request field, and then preview the resulting Dataframe we have thusfar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b860a8f-977b-4018-b36c-a9378ad93acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+----------------------------------+------+-----+----------------------------------+------+---------------------+\n",
      "|ip_address    |timestamp                 |request                           |status|bytes|user_agent                        |method|endpoint             |\n",
      "+--------------+--------------------------+----------------------------------+------+-----+----------------------------------+------+---------------------+\n",
      "|66.249.75.159 |29/Nov/2015:03:50:05 +0000|GET /robots.txt HTTP/1.1          |200   |55   |-                                 |GET   |/robots.txt          |\n",
      "|66.249.75.168 |29/Nov/2015:03:50:06 +0000|GET /blog/ HTTP/1.1               |200   |8083 |-                                 |GET   |/blog/               |\n",
      "|185.71.216.232|29/Nov/2015:03:53:15 +0000|POST /wp-login.php HTTP/1.1       |200   |1691 |http://nohatenews.com/wp-login.php|POST  |/wp-login.php        |\n",
      "|54.165.199.171|29/Nov/2015:04:32:27 +0000|GET /sitemap_index.xml HTTP/1.0   |200   |592  |-                                 |GET   |/sitemap_index.xml   |\n",
      "|54.165.199.171|29/Nov/2015:04:32:27 +0000|GET /post-sitemap.xml HTTP/1.0    |200   |2502 |-                                 |GET   |/post-sitemap.xml    |\n",
      "|54.165.199.171|29/Nov/2015:04:32:27 +0000|GET /page-sitemap.xml HTTP/1.0    |200   |11462|-                                 |GET   |/page-sitemap.xml    |\n",
      "|54.165.199.171|29/Nov/2015:04:32:27 +0000|GET /category-sitemap.xml HTTP/1.0|200   |585  |-                                 |GET   |/category-sitemap.xml|\n",
      "|54.165.199.171|29/Nov/2015:04:32:27 +0000|GET /blog/ HTTP/1.0               |200   |31746|-                                 |GET   |/blog/               |\n",
      "|54.165.199.171|29/Nov/2015:04:32:27 +0000|GET /orlando-sports/ HTTP/1.0     |200   |35510|-                                 |GET   |/orlando-sports/     |\n",
      "|54.165.199.171|29/Nov/2015:04:32:37 +0000|GET /about/ HTTP/1.0              |200   |25121|-                                 |GET   |/about/              |\n",
      "+--------------+--------------------------+----------------------------------+------+-----+----------------------------------+------+---------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Split request field to get HTTP method and endpoint\n",
    "parsed_logs_df = cleaned_df.withColumn(\"method\", regexp_extract(\"request\", r'(\\S+)', 1)) \\\n",
    "                               .withColumn(\"endpoint\", regexp_extract(\"request\", r' (\\S+) ', 1))\n",
    "\n",
    "# Show parsed log data\n",
    "parsed_logs_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ae1b2c-bb61-4e38-ad39-aba7c619da18",
   "metadata": {},
   "source": [
    "Now let's start doing some analysis. We'll start with displaying the top 10 IP addresses. Unfortunately, as usual, there's a hacker trying to DOS me:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ced343-cde5-4c6c-a835-f08a6fc7cacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|    ip_address|request_count|\n",
      "+--------------+-------------+\n",
      "| 46.166.139.20|        68487|\n",
      "|54.165.199.171|         4381|\n",
      "|195.154.250.88|         1723|\n",
      "| 97.100.169.53|          240|\n",
      "| 62.210.88.201|           81|\n",
      "|  66.249.66.59|           69|\n",
      "|  66.249.66.62|           54|\n",
      "|   66.249.66.3|           47|\n",
      "|   52.91.1.103|           39|\n",
      "| 172.56.26.235|           24|\n",
      "+--------------+-------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. Count requests per IP address\n",
    "ip_count_df = parsed_logs_df.groupBy(\"ip_address\").agg(count(\"*\").alias(\"request_count\")).orderBy(desc(\"request_count\"))\n",
    "ip_count_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b7b59-49e9-43c4-98a2-5972e3a9d442",
   "metadata": {},
   "source": [
    "Let's look at the top endpoints, and right away we can see that our friend is trying to break into my WordPress site through xmlrpc.php vulnerabilities and trying to brute-force their way in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b592ffaf-cec4-4101-babe-4f631f12b908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|            endpoint|endpoint_count|\n",
      "+--------------------+--------------+\n",
      "|         /xmlrpc.php|         68494|\n",
      "|       /wp-login.php|          1923|\n",
      "|                   /|           336|\n",
      "|              /blog/|           138|\n",
      "|         /robots.txt|           123|\n",
      "|   /post-sitemap.xml|           118|\n",
      "|  /sitemap_index.xml|           118|\n",
      "|   /page-sitemap.xml|           117|\n",
      "|/category-sitemap...|           117|\n",
      "| /orlando-headlines/|            95|\n",
      "+--------------------+--------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# 2. Most requested endpoints\n",
    "endpoint_count_df = parsed_logs_df.groupBy(\"endpoint\").agg(count(\"*\").alias(\"endpoint_count\")).orderBy(desc(\"endpoint_count\"))\n",
    "endpoint_count_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3703ce2-66df-4237-a0f8-89fc55a00e05",
   "metadata": {},
   "source": [
    "Let's also take a look at the top status codes. Looks like they've succeeded in making my site unstable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a849fd5e-a529-4688-9201-d93300e4e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|status|status_count|\n",
      "+------+------------+\n",
      "|   200|       64965|\n",
      "|   500|       10714|\n",
      "|   301|         159|\n",
      "|   404|          24|\n",
      "|   400|           2|\n",
      "|   302|           2|\n",
      "|   405|           1|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. HTTP status code distribution\n",
    "status_count_df = parsed_logs_df.groupBy(\"status\").agg(count(\"*\").alias(\"status_count\")).orderBy(desc(\"status_count\"))\n",
    "status_count_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1fcdd-dd63-477f-96c3-3512a4baa67b",
   "metadata": {},
   "source": [
    "Finally we'll shut things down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa05da8-3c09-49fd-91fe-824e647dd075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310b049-80f6-47b2-950a-d5b60dad2c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
